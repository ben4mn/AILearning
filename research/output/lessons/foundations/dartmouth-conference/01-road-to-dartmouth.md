# The Road to Dartmouth

## Introduction

By the mid-1950s, something was in the air. Across multiple institutions, researchers were independently pursuing a tantalizing idea: could machines be made to think? Alan Turing had posed the question philosophically. McCulloch and Pitts had shown that neural networks could compute. Shannon had created information theory. Von Neumann was building digital computers.

But these threads remained separate. There was no unified field, no community, no shared vocabulary. That was about to change. In 1955, a young mathematician named John McCarthy began planning a summer workshop that would bring these scattered researchers together and, in the process, give birth to a new science.

In this lesson, we'll explore the intellectual currents that led to the Dartmouth Conference—the people, ideas, and circumstances that set the stage for artificial intelligence to emerge as a distinct field.

## The Key Figures

Four researchers would become the principal organizers of the Dartmouth workshop. Understanding their backgrounds helps explain what they hoped to achieve.

### John McCarthy (1927-2011)

McCarthy was a mathematician who had studied at Caltech and Princeton. He was fascinated by the question of how to formalize common-sense reasoning—the kind of thinking that lets humans navigate everyday situations effortlessly.

At the time, McCarthy was at Dartmouth College, a small Ivy League school in New Hampshire. He would later move to Stanford and MIT, becoming one of the most influential figures in AI history. He invented LISP, the programming language that dominated AI for decades, and coined the very term "artificial intelligence."

McCarthy was ambitious and organizing by nature. When he saw related work happening in isolation, he wanted to bring it together.

### Marvin Minsky (1927-2016)

Minsky was a polymath—trained in mathematics, physics, psychology, and neuroscience. While at Princeton, he had built one of the first neural network learning machines, a 40-neuron device with random connections that could learn simple patterns.

Minsky had deep interests in how minds work and how machines might replicate mental processes. He would become McCarthy's lifelong collaborator and occasional rival, eventually founding the MIT AI Lab and becoming perhaps the most visible AI researcher of his generation.

In 1955, Minsky was finishing his PhD at Princeton, already known for creative thinking about computation and cognition.

### Nathaniel Rochester (1919-2001)

Rochester was an engineer at IBM, where he had designed the architecture of the IBM 701—one of the first commercial scientific computers. He brought an industrial perspective and, crucially, access to computing resources.

Rochester was interested in modeling thought processes on computers. He had conducted some of the first computer simulations of neural networks at IBM, implementing simplified versions of Hebb's theory to see if networks could learn.

His involvement meant the workshop would have practical grounding in what computers could actually do, not just theoretical speculation.

### Claude Shannon (1916-2001)

Shannon was already a legend. His 1948 paper "A Mathematical Theory of Communication" had created the field of information theory, revolutionizing telecommunications and providing the mathematical foundation for the digital age.

Shannon had also written a master's thesis showing that Boolean algebra could design electrical switching circuits—a key insight for digital computing. His later work included chess-playing programs and theories about optimal strategies.

Shannon's name on the proposal lent enormous prestige. His participation signaled that this was serious science, not science fiction.

## Converging Intellectual Streams

Several research threads were converging by 1955:

### Automata Theory

Von Neumann, inspired by McCulloch and Pitts, was developing a theory of self-reproducing automata. Could machines build copies of themselves? Could computation be explained as a general phenomenon independent of physical substrate?

These questions suggested that intelligence might be substrate-independent—it wouldn't matter whether neurons or transistors did the computing.

### Cybernetics

Norbert Wiener's cybernetics movement (1948 and after) explored parallels between biological and mechanical systems. Feedback loops, control systems, and information processing were proposed as universal principles applying to both.

Cybernetics brought engineers, biologists, and psychologists into conversation. It created an interdisciplinary spirit that the AI founders would inherit.

### Game Theory and Decision Making

Von Neumann and Morgenstern's *Theory of Games and Economic Behavior* (1944) showed that strategic decision-making could be formalized mathematically. Shannon and Turing both wrote about game-playing machines.

If machines could play games—even simple ones—perhaps they could reason about goals, strategies, and opponents.

### Symbolic Logic and Computation

The connection between logic and computation was becoming clear. Turing had shown that logical reasoning could be mechanized. Programs were essentially logical instructions. Could higher-level reasoning—proof, inference, planning—also be programmed?

### The New Computers

By 1955, electronic computers had evolved from classified wartime projects to (somewhat) available research tools. The UNIVAC, IBM 701, and other machines offered unprecedented computational power.

For the first time, researchers could test ideas about machine intelligence empirically, not just theoretically.

## The Proposal

In September 1955, McCarthy drafted a proposal for summer funding to the Rockefeller Foundation. Titled "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence," it's remarkable for both its ambition and its specificity.

The opening paragraph stated the core hypothesis:

> "We propose that a 2 month, 10 man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it."

This was bold. The proposal claimed not just that some aspects of intelligence could be mechanized, but every aspect. Learning, creativity, self-improvement—all could be simulated given precise enough descriptions.

The proposal then listed specific problems to be studied:

1. **Automatic Computers**: How to program computers to use language, form abstractions, and improve themselves
2. **How a Computer Can Be Programmed to Use a Language**: Moving beyond mathematical notation to more flexible communication
3. **Neuron Nets**: How networks of simple units might give rise to complex behaviors
4. **Theory of the Size of a Calculation**: Measuring computational complexity
5. **Self-Improvement**: How machines might improve their own performance
6. **Abstractions**: How to form abstract concepts from concrete experiences
7. **Randomness and Creativity**: The role of randomness in creative problem-solving

Each topic reflected ongoing work by one or more of the proposers or their intended invitees.

## Why "Artificial Intelligence"?

McCarthy coined the term "artificial intelligence" specifically for this proposal. But why that phrase?

Alternative names were possible:
- "Automata studies" (too focused on formal systems)
- "Cybernetics" (already associated with Wiener's specific approach)
- "Complex information processing" (too vague)
- "Machine intelligence" (used by some British researchers)
- "Thinking machines" (too science-fictional)

McCarthy chose "artificial intelligence" deliberately. "Artificial" suggested human creation, distinguishing the field from studying natural intelligence. "Intelligence" was more ambitious than "information processing"—it claimed the domain of cognition, not just computation.

The term also served a political purpose: it declared independence from cybernetics and from Wiener, with whom some of the proposers had complicated relationships.

Not everyone loved the name. Some thought it oversold what was achievable; others found it imprecise. But it stuck, and we've used it ever since.

## Funding and Planning

The Rockefeller Foundation agreed to fund the workshop—$7,500 for the summer, covering participant expenses. This was modest funding even by 1956 standards, but enough to make the gathering possible.

McCarthy and Minsky were the primary organizers. They invited about twenty researchers, expecting perhaps ten to attend for the full two months. Some would come for shorter periods.

The workshop was set for June to August 1956, at Dartmouth's Hanover campus. The location was deliberate: removed from the distractions of major cities, a place where participants could focus intensively on problems.

Expectations were high—perhaps unrealistically so. The proposal suggested that significant progress on machine intelligence might be made in a single summer. This optimism would become characteristic of early AI, and would eventually contribute to disillusionment when quick progress proved elusive.

## Key Takeaways

- By the mid-1950s, multiple research threads (automata theory, cybernetics, game theory, symbolic logic, new computers) were converging on questions about machine intelligence
- John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon organized a summer workshop to unite these threads
- McCarthy coined the term "artificial intelligence" for the proposal, distinguishing the new field from cybernetics
- The proposal's core conjecture—that every aspect of intelligence can be precisely described and simulated—was ambitious and would define the field's agenda
- The Rockefeller Foundation funded the workshop, set for summer 1956 at Dartmouth College

## Further Reading

- McCarthy, John, et al. "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence." (1955) - The original proposal, available online
- Kline, Ronald. *The Cybernetics Moment: Or Why We Call Our Age the Information Age* (2015) - Context on cybernetics and its relationship to AI
- Crevier, Daniel. *AI: The Tumultuous History of the Search for Artificial Intelligence* (1993) - Chapter on the founding of AI
- McCorduck, Pamela. *Machines Who Think* (2nd ed., 2004) - Comprehensive history including detailed Dartmouth coverage

---
*Estimated reading time: 8 minutes*
