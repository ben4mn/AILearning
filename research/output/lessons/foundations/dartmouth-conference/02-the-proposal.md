# The Proposal

## Introduction

In August 1955, a two-page document was sent to the Rockefeller Foundation that would reshape the intellectual landscape of the twentieth century. "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence" didn't just request funding for a summer workshop—it declared the founding manifesto of a new science.

The proposal is remarkable for what it claimed, what it promised, and what it got wrong. Reading it today, we can see both the visionary ambition that launched the field and the overconfidence that would lead to its first disappointments.

In this lesson, we'll examine the proposal in detail, understanding its key claims, its proposed research agenda, and its lasting influence on how we think about machine intelligence.

## The Central Conjecture

The proposal's opening contains its boldest claim:

> "The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it."

Let's unpack this carefully:

**"Every aspect"**: Not just calculation or logic, but learning, creativity, language, perception—the full scope of human cognition.

**"In principle"**: The claim is about theoretical possibility, not immediate practicality. Given enough time and effort, any cognitive process could be formalized.

**"Precisely described"**: Intelligence, however mysterious it seems, is ultimately lawful. There are processes underlying thought that can be specified exactly.

**"Simulate"**: Machines wouldn't necessarily replicate the biological mechanism—they would recreate the functional behavior. This distinction between simulation and replication would become central to AI philosophy.

This conjecture—now sometimes called the "physical symbol system hypothesis" in its later formulations—was controversial even then. Critics argued that human minds have non-computable aspects, that consciousness cannot be simulated, that meaning cannot arise from symbol manipulation.

But for the proposal's authors, it was a working hypothesis, not a proven theorem. They wanted to explore how far the conjecture could take them.

## The Seven Research Topics

The proposal outlined seven areas for investigation. Each reflected ongoing work and open questions:

### 1. Automatic Computers

> "If a machine can do a job, then an automatic calculator can be programmed to simulate the machine."

This established the computer as the universal medium for AI research. Whatever intelligence is, it can be implemented on a general-purpose computer. There's nothing special about biological neurons that silicon can't replicate.

The proposal noted that existing computers were "being used for more and more practical purposes"—a reminder of how new digital computers were in 1955.

### 2. How a Computer Can Be Programmed to Use a Language

> "It may be speculated that a large part of human thought consists of manipulating words according to rules of reasoning and rules of conjecture."

Language was seen as central to intelligence. The proposal noted that machines would need to handle natural language, not just formal notation. This foreshadowed decades of research in computational linguistics and, eventually, large language models.

The reference to "rules of conjecture" is intriguing—even in 1955, the authors recognized that reasoning isn't purely deductive.

### 3. Neuron Nets

> "How can a set of (hypothetical) neurons be arranged so as to form concepts?"

This section acknowledged the neural network approach pioneered by McCulloch, Pitts, Hebb, and others. Rochester had been simulating neural networks at IBM.

But the proposal was notably less enthusiastic about neural networks than about symbolic approaches. The authors suggested that "partial results" existed but that the "fundamental notions" were still unclear. This ambivalence foreshadowed AI's long internal debate between neural and symbolic approaches.

### 4. Theory of the Size of a Calculation

> "If we are given a well-defined problem (one for which it is possible to test mechanically whether or not a proposed answer is a valid answer) one way of solving it is to try all possible answers in order."

This anticipated computational complexity theory. The proposal recognized that brute-force search through all possibilities was often impractical. Smart machines would need to find shortcuts—heuristics, search strategies, ways to prune the solution space.

Shannon had worked on this for chess, calculating that examining all possible games would take more time than the universe's age. Intelligent play required selective attention.

### 5. Self-Improvement

> "Probably a truly intelligent machine will carry out activities which may best be described as self-improvement."

This may be the most prescient section. The proposal envisioned machines that improve their own performance:

> "Some schemes for doing this have been proposed and are worth further study."

The specific schemes mentioned included Samuel's checkers-playing program, which learned from experience. Machine learning—the field that would eventually revolutionize AI—was present at the founding.

The proposal also speculated about machines that modify their own code:

> "It seems likely that this question can be studied abstractly as well."

The abstract study of self-improvement connects to later work on meta-learning and recursive self-improvement.

### 6. Abstractions

> "A number of types of 'abstraction' can be distinctly defined and several others less distinctly."

The proposal recognized that intelligence requires moving from specific instances to general concepts. How does a child form the concept of "dog" from seeing many different dogs?

This section was vaguer than others—abstraction was recognized as important but not well understood. It remains a central challenge in AI: neural networks can classify but struggle with the kind of compositional abstraction humans perform effortlessly.

### 7. Randomness and Creativity

> "A fairly attractive and yet clearly incomplete conjecture is that the difference between creative thinking and unimaginative competent thinking lies in the injection of a some randomness."

Could creativity be explained as systematic exploration plus random variation? This idea—that novel ideas come from random recombination followed by selection—connects to evolution and to modern techniques like random search and stochastic methods.

The proposal was careful to call this "incomplete"—creativity wasn't just randomness. But randomness might be an ingredient.

## What's Not in the Proposal

Reading between the lines reveals interesting absences:

**No detailed timeline**: The proposal doesn't promise specific results by specific dates. This was wise, given how long AI's challenges would prove.

**Limited discussion of embodiment**: The proposal focuses on reasoning, language, and learning. Robotics, perception, and physical interaction get little attention.

**No consideration of ethics**: Questions about the social impact of intelligent machines, now urgent, were not raised. The focus was purely on whether and how AI could be built.

**No acknowledgment of difficulty**: The tone is optimistic throughout. Challenges are mentioned but never described as possibly insurmountable.

## Signatures and Credibility

The proposal was signed by all four organizers:
- J. McCarthy, Dartmouth College
- M. L. Minsky, Harvard University (he was a Junior Fellow)
- N. Rochester, IBM
- C. E. Shannon, Bell Telephone Laboratories

This combination—academia and industry, East Coast institutions and corporate research—lent credibility. The Rockefeller Foundation was funding established researchers at respected institutions, not speculative dreamers.

Shannon's name was particularly important. As the father of information theory, his endorsement signaled that AI was continuous with serious technical work.

## Reception and Funding

The Rockefeller Foundation approved the proposal, granting $7,500. This was modest—perhaps $80,000 in today's terms—but sufficient for a summer workshop.

The funding covered:
- Travel expenses for participants
- Room and board at Dartmouth
- Some secretarial support

It did not fund equipment or extensive computation. Participants would bring their ideas, not their machines.

The approval letter came in early 1956. Planning could proceed for the summer workshop.

## Legacy of the Proposal

The 1955 proposal established several things that would persist:

**A name**: "Artificial intelligence" became the field's identity, despite later objections.

**A research agenda**: The seven topics mapped the field for decades. Language, learning, abstraction, complexity—these remained central.

**An attitude**: The conjecture that all intelligence is formalizable set an ambitious tone. AI researchers would aim high, not settle for mere automation.

**A community**: By naming the field and gathering its founders, the proposal created a scientific community where none existed.

**A style**: The proposal's confidence—its willingness to speculate boldly while acknowledging uncertainties—characterized early AI culture.

Critics would later accuse the proposal of hubris. But viewed charitably, it was a bold hypothesis, put forward explicitly so it could be tested. Science advances through such conjectures.

## Key Takeaways

- The proposal's central conjecture—that every aspect of intelligence can be precisely described and simulated—defined AI's founding assumption
- Seven research areas were identified: computers, language, neural networks, computation theory, self-improvement, abstraction, and creativity
- The proposal favored symbolic approaches over neural networks, foreshadowing decades of debate
- McCarthy coined "artificial intelligence" to name the field, distinguishing it from cybernetics
- The modest funding ($7,500) was enough to launch a scientific revolution

## Further Reading

- McCarthy, J., Minsky, M., Rochester, N., & Shannon, C. "A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence." (1955) - [Available online at formal.stanford.edu]
- Solomonoff, Ray. "The Time Scale of Artificial Intelligence: Reflections on Social Effects." *Human Systems Management* 5 (1985): 149-153 - Reflections by a Dartmouth attendee
- Nilsson, Nils. *The Quest for Artificial Intelligence: A History of Ideas and Achievements* (2010) - Chapter 4 covers the proposal in context
- Buchanan, Bruce. "A (Very) Brief History of Artificial Intelligence." *AI Magazine* 26, no. 4 (2005): 53-60

---
*Estimated reading time: 8 minutes*
